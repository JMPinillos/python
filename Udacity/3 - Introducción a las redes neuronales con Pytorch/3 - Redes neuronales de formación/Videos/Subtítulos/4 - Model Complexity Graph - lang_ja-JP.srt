1
00:00:00,000 --> 00:00:02,129
さて 前回の続きから始めましょう

2
00:00:02,129 --> 00:00:04,795
ネットワークアーキテクチャが
非常に複雑なので

3
00:00:04,796 --> 00:00:08,929
それに対応しなければ
なりません

4
00:00:08,929 --> 00:00:11,509
トレーニングのプロセスを
見てみましょう

5
00:00:11,509 --> 00:00:15,929
最初のエポックでは
ランダムな重みから始めますが

6
00:00:15,929 --> 00:00:17,885
このモデルでは
エラーが発生します

7
00:00:17,885 --> 00:00:22,524
トレーニング後 20エポックでは
良いモデルが得られたとします

8
00:00:22,524 --> 00:00:26,085
その後 エポックを100回続けると

9
00:00:26,085 --> 00:00:28,196
データの適合率が向上し

10
00:00:28,196 --> 00:00:30,589
次第に過剰適合が始まります

11
00:00:30,588 --> 00:00:32,219
さらに続けて

12
00:00:32,219 --> 00:00:36,325
600エポックになると
重大な過剰適合になります

13
00:00:36,325 --> 00:00:42,399
青い領域は 青い点を中心とした
円の集まりです

14
00:00:42,399 --> 00:00:44,390
トレーニングデータに適合しますが

15
00:00:44,390 --> 00:00:46,590
頂点の間引きになります

16
00:00:46,590 --> 00:00:49,170
青い領域に新しい青い点があるのを
想像してください

17
00:00:49,170 --> 00:00:54,140
この点は 青に近い場合を除き
赤に分類される可能性が高くなります

18
00:00:54,140 --> 00:01:00,445
そこで この点のようなテストセットを
追加して モデルを評価してみましょう

19
00:01:00,445 --> 00:01:03,060
トレーニングセットと
テストセットの誤差を

20
00:01:03,060 --> 00:01:06,209
各エポックに対して
プロットしてみましょう

21
00:01:06,209 --> 00:01:07,865
最初のエポックでは

22
00:01:07,864 --> 00:01:09,869
モデルが完全にランダムなので

23
00:01:09,870 --> 00:01:14,840
トレーニングセットとテストセットの
両方を誤分類します

24
00:01:14,840 --> 00:01:18,284
そのため トレーニングもテストも
誤差が大きくなります

25
00:01:18,284 --> 00:01:19,844
ここでプロットします

26
00:01:19,843 --> 00:01:21,493
20エポックでは

27
00:01:21,493 --> 00:01:25,152
トレーニングデータに適合した
優れたモデルになり

28
00:01:25,152 --> 00:01:27,608
テストセットでも
良い結果が得られました

29
00:01:27,608 --> 00:01:32,669
どちらの誤差も比較的小さいので
ここでプロットしてみます

30
00:01:32,670 --> 00:01:34,417
100エポックでは

31
00:01:34,417 --> 00:01:36,358
過剰適合が始まります

32
00:01:36,358 --> 00:01:41,479
このモデルはデータに適合していますが
テストデータでミスが始まります

33
00:01:41,480 --> 00:01:44,316
トレーニングの誤差は
減少し続けていますが

34
00:01:44,316 --> 00:01:46,838
テストの誤差は増加し始めます

35
00:01:46,837 --> 00:01:48,393
では ここでプロットします

36
00:01:48,394 --> 00:01:51,795
600エポックでは ひどい
過剰適合になります

37
00:01:51,795 --> 00:01:56,189
これは トレーニングの誤差が
非常に小さいことを示していますが

38
00:01:56,188 --> 00:02:00,858
テストデータではモデルに
大量のミスが発生しています

39
00:02:00,858 --> 00:02:03,113
テストの誤差が大きいのです

40
00:02:03,114 --> 00:02:04,939
ここでプロットします

41
00:02:04,938 --> 00:02:09,938
トレーニングとテストの誤差を
結ぶ曲線を描きます

42
00:02:09,938 --> 00:02:11,353
このプロットでは

43
00:02:11,354 --> 00:02:15,850
未学習から過剰適合に移ると

44
00:02:15,850 --> 00:02:20,610
モデルをトレーニングするので
学習曲線は減少し

45
00:02:20,610 --> 00:02:23,569
トレーニングデータの適合性が
さらに向上します

46
00:02:23,568 --> 00:02:29,193
モデルが不正確で未学習の間は
テストの誤差が大きくなります

47
00:02:29,193 --> 00:02:33,038
その後 モデルが
汎化するにつれて減少し

48
00:02:33,038 --> 00:02:37,158
ゴルディロックスポットと呼ばれる
最小点に到達します

49
00:02:37,158 --> 00:02:40,030
最終的に そのスポットを過ぎると

50
00:02:40,030 --> 00:02:43,205
モデルは汎化をやめて
トレーニングデータを

51
00:02:43,205 --> 00:02:47,530
記憶するようになるので
再び過剰適合になります

52
00:02:47,530 --> 00:02:50,783
このグラフは複雑性グラフと
呼ばれます

53
00:02:50,783 --> 00:02:53,438
Y軸は 誤差の大きさ

54
00:02:53,438 --> 00:02:59,204
X軸は モデルの複雑さを
表しています

55
00:02:59,205 --> 00:03:01,960
この場合は エポック数を表しています

56
00:03:01,960 --> 00:03:03,550
ご覧のように

57
00:03:03,550 --> 00:03:08,064
左はテストとトレーニングの
誤差が大きく 未学習になっています

58
00:03:08,064 --> 00:03:14,843
右側は テストエラーが多く
トレーニング誤差が少ない

59
00:03:14,843 --> 00:03:16,478
過剰適合になっています

60
00:03:16,479 --> 00:03:19,335
その中間には ちょうどよい

61
00:03:19,335 --> 00:03:22,740
ゴルディロックスポイントが
あります

62
00:03:22,740 --> 00:03:25,314
これで 使用する
エポックの数が決まります

63
00:03:25,313 --> 00:03:31,644
つまり

64
00:03:31,645 --> 00:03:34,044
テストの誤差が減少しなくなり
増加し始めるまで降下します

65
00:03:34,044 --> 00:03:40,090
その時点で停止します

