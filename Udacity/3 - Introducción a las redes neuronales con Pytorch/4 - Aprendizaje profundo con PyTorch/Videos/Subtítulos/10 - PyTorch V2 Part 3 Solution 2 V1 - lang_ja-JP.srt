1
00:00:00,000 --> 00:00:04,620
こんにちは 

2
00:00:04,620 --> 00:00:07,620
実装してもらった
トレーニングパスの解答がこちらです

3
00:00:07,620 --> 00:00:10,109
この部分は 通常通りにモデルを定義し

4
00:00:10,109 --> 00:00:13,094
確率的勾配降下法を使用して

5
00:00:13,095 --> 00:00:15,510
負の対数尤度損失を定義し パラメータに渡しています

6
00:00:15,509 --> 00:00:18,149
これがトレーニングパスです

7
00:00:18,149 --> 00:00:23,189
trainloaderのラベルの各画像について

8
00:00:23,190 --> 00:00:26,970
平坦化を行い オプティマイザzero_gradを
使用して勾配をゼロにします

9
00:00:26,969 --> 00:00:28,820
outputでモデルを介して 画像を順方向に送り 

10
00:00:28,820 --> 00:00:31,129
そこから 損失を計算します

11
00:00:31,129 --> 00:00:32,960
そしてバックワードパスを実行したら
最後に勾配で

12
00:00:32,960 --> 00:00:36,259
オプティマイザのステップを
行うことができます

13
00:00:36,259 --> 00:00:40,304
これを実行して トレーニングを少し待てば

14
00:00:40,304 --> 00:00:41,924
時間経過と共に 損失が減少するのを
確認できるはずです

15
00:00:41,924 --> 00:00:43,379
５回のエポックの後で

16
00:00:43,380 --> 00:00:47,429
最初のエポックを見ると
かなり高い数値の1.9から開始していますが

17
00:00:47,429 --> 00:00:51,950
５回のエポックの後は

18
00:00:51,950 --> 00:00:54,950
トレーニングを重ねるほど減少し

19
00:00:54,950 --> 00:00:58,445
最後には かなり低くなっていることが分かります

20
00:00:58,445 --> 00:01:00,740
つまりトレーニングを続けると

21
00:01:00,740 --> 00:01:05,655
ネットワークのデータ学習は 向上し続け
training lossは 小さくなります

22
00:01:05,655 --> 00:01:08,700
このトレーニングネットワークでは

23
00:01:08,700 --> 00:01:11,630
これらの画像が 何であるか
ネットワークの考えを

24
00:01:11,629 --> 00:01:14,609
実際に確認することができます

25
00:01:14,609 --> 00:01:19,189
ここで画像に移すことができます

26
00:01:19,189 --> 00:01:23,480
この例では 数字の２の画像です

27
00:01:23,480 --> 00:01:29,460
そしてこれが ネットワークの予測です

28
00:01:29,459 --> 00:01:31,654
ほとんどの確率 つまりの予測の大部分が
数字２のクラスに

29
00:01:31,655 --> 00:01:34,969
当てられているのを簡単に
見てとることができます

30
00:01:34,969 --> 00:01:37,730
数字の８でも試してみましょう

31
00:01:37,730 --> 00:01:41,420
この場合は 数字の８が予測されています

32
00:01:41,420 --> 00:01:46,070
数字の予測が 正しく行えるように
ネットワークをトレーニングすることができました

