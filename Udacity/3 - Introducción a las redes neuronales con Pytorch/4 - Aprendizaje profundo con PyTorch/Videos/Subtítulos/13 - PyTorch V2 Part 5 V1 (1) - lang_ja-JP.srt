1
00:00:00,000 --> 00:00:01,695
皆さんこんにちは

2
00:00:01,695 --> 00:00:04,785
推論と検証についての話をしましょう

3
00:00:04,785 --> 00:00:06,915
トレーニングされている
ネットワークがある場合

4
00:00:06,915 --> 00:00:09,554
通常は 予測を行うのに
利用したくなります

5
00:00:09,554 --> 00:00:11,070
これは推論と呼ばれ

6
00:00:11,070 --> 00:00:13,349
統計学の用語に由来しています

7
00:00:13,349 --> 00:00:16,620
しかしニューラルネットワークは

8
00:00:16,620 --> 00:00:18,359
データのトレーニングを
うまく処理しすぎる傾向があり

9
00:00:18,359 --> 00:00:21,169
ネットワークが確認したことのない
データを一般化できません

10
00:00:21,170 --> 00:00:22,940
これは過剰適合と呼ばれます

11
00:00:22,940 --> 00:00:27,585
トレーニングセットの
トレーニングを強化し続けると

12
00:00:27,585 --> 00:00:29,719
トレーニングセットに存在するが
あらゆる手書き数字の一般的な

13
00:00:29,719 --> 00:00:32,045
データセットには存在しない相関関係や

14
00:00:32,045 --> 00:00:37,025
パターンをネットワークが拾い始めます

15
00:00:37,024 --> 00:00:39,304
ですから過剰適合のテストを行うには

16
00:00:39,304 --> 00:00:45,259
トレーニングセットにないデータで
ネットワークのパフォーマンスを測定します

17
00:00:45,259 --> 00:00:48,439
このデータは通常 検証セットまたは
テストセットと呼ばれます

18
00:00:48,439 --> 00:00:52,369
したがって 検証セットの
パフォーマンスを測定している際

19
00:00:52,369 --> 00:00:57,544
ドロップアウトなどの正則化を通じた
過剰適合も削減するように試行しました

20
00:00:57,545 --> 00:00:58,895
そこで このノートでは

21
00:00:58,895 --> 00:01:02,705
検証セットを確認するだけでなく
ドロップアウトも使用して

22
00:01:02,704 --> 00:01:06,984
過剰適合を軽減する方法を説明します

23
00:01:06,984 --> 00:01:10,829
PyTorchなどからデータの
トレーニングセットを得るには

24
00:01:10,829 --> 00:01:14,855
トレーニングが真でありfashionMNISTに
対するものであると言います

25
00:01:14,855 --> 00:01:16,070
テストセットを得るには

26
00:01:16,069 --> 00:01:18,394
ここでtrain = Falseを実際に設定します

27
00:01:18,394 --> 00:01:21,174
以前と同様
モデルを定義しているだけです

28
00:01:21,174 --> 00:01:24,200
検証の目標はトレーニングセットの
一部ではないデータのモデルの

29
00:01:24,200 --> 00:01:28,189
パフォーマンスを測定することです

30
00:01:28,189 --> 00:01:31,804
しかし パフォーマンスの意味は 利用者

31
00:01:31,805 --> 00:01:34,105
開発者 コードを書いている人により 異なります

32
00:01:34,105 --> 00:01:37,005
多くの場合 精度として表されます

33
00:01:37,004 --> 00:01:40,969
すなわち すべての予測と比較して

34
00:01:40,969 --> 00:01:45,340
モデルがどれだけ多くの
正しい分類を行ったか ということです

35
00:01:45,340 --> 00:01:48,500
測定基準の他の選択肢は
精度と再現率で

36
00:01:48,500 --> 00:01:50,614
上位５位の誤り率です

37
00:01:50,614 --> 00:01:55,474
ここでは検証セットの精度を
実際に測定する方法を説明します

38
00:01:55,474 --> 00:01:58,390
最初にテストセットからの１つのバッチ
であるフォワードパスを行います

39
00:01:58,390 --> 00:02:01,849
テストセットで確率を
得られるのが分かります

40
00:02:01,849 --> 00:02:05,209
１つのバッチに64の例があるだけです

41
00:02:05,209 --> 00:02:08,180
次に各クラスに対する
10の列があります

42
00:02:08,180 --> 00:02:11,330
精度については イメージが与えられたときに
モデルがクラスについて

43
00:02:11,330 --> 00:02:14,445
正しい予測を行っているか 確認します

44
00:02:14,444 --> 00:02:19,219
検討できる予測は

45
00:02:19,219 --> 00:02:24,780
最高の確率の
クラスのものになります

46
00:02:24,780 --> 00:02:27,194
ですから このためにtopkメソッドを
テンソルに使用できます

47
00:02:27,194 --> 00:02:29,264
kの最高値を返します

48
00:02:29,264 --> 00:02:33,104
１を渡すと

49
00:02:33,104 --> 00:02:38,560
これにより１つの最高の値が得られます

50
00:02:38,560 --> 00:02:40,754
この最高値はネットワークが
推測する可能性が最も高いクラスです

51
00:02:40,754 --> 00:02:45,340
最初の10の例そして

52
00:02:45,340 --> 00:02:50,500
提示したテストデータの
このバッチに対しては

53
00:02:50,500 --> 00:02:53,090
クラス４とクラス５がこれらに
予測されているものになります

54
00:02:53,090 --> 00:02:55,370
このネットワークが まだトレーニング
されていないことに注意してください

55
00:02:55,370 --> 00:02:58,689
ランダムな推測を行うにすぎません

56
00:02:58,689 --> 00:03:01,669
実際には データについて何も
把握していないのです

57
00:03:01,669 --> 00:03:04,459
topkは２つのテンソルの
タプルを返します

58
00:03:04,460 --> 00:03:07,760
１つ目のテンソルは
実際の確率の値で

59
00:03:07,759 --> 00:03:10,594
２つ目のテンソルはクラスの
インデックスそのものです

60
00:03:10,594 --> 00:03:16,219
通常はこのtop_classを
ここで必要とするだけです

61
00:03:16,219 --> 00:03:18,745
topkを呼び出して
クラスで確率を分けています

62
00:03:18,745 --> 00:03:22,849
この後はこのtop_classを
使用するだけです

63
00:03:22,849 --> 00:03:25,085
ネットワークからクラスを推測したので

64
00:03:25,085 --> 00:03:28,590
trueのラベルと比較できます

65
00:03:28,590 --> 00:03:31,310
したがってtop_classが
ラベルと等価だと言えます

66
00:03:31,310 --> 00:03:34,699
ここでの唯一のコツは

67
00:03:34,699 --> 00:03:39,519
top_classテンソルとラベルテンソルを
同じ形にすることです

68
00:03:39,520 --> 00:03:47,480
すると 予想した通り等価となります

69
00:03:47,479 --> 00:03:52,239
テストローダーのラベルは64の
要素のある１次元のテンソルですが

70
00:03:52,240 --> 00:03:57,844
top_classそのものは２次元
のテンソルで(64, 1)です

71
00:03:57,844 --> 00:04:01,250
top_classの形に一致するように
ラベルの形を変えてみたいと思います

72
00:04:01,250 --> 00:04:03,014
これによりequalsテンソルが得られます

73
00:04:03,014 --> 00:04:04,519
どのようになるか見てみましょう

74
00:04:04,520 --> 00:04:05,990
０と１がたくさん出ます

75
00:04:05,990 --> 00:04:07,745
０は一致しないところで

76
00:04:07,745 --> 00:04:10,985
１は一致するところです

77
00:04:10,985 --> 00:04:14,850
多数の０と１から成るテンソルがあります

78
00:04:14,849 --> 00:04:17,355
精度を知りたいですよね？

79
00:04:17,355 --> 00:04:18,600
すべての正しいものを足して

80
00:04:18,600 --> 00:04:20,960
すべての正しい予測を足してから

81
00:04:20,959 --> 00:04:23,779
予測の総数で割ります

82
00:04:23,779 --> 00:04:25,954
テンソルがすべて０と１の場合

83
00:04:25,954 --> 00:04:27,939
平均をとるのと同じです

84
00:04:27,939 --> 00:04:32,649
torch.meanを実行します

85
00:04:32,649 --> 00:04:36,099
しかし問題はequalsが
バイトテンソルであり

86
00:04:36,100 --> 00:04:39,335
torch.meanはバイトテンソルでは
機能しないことです

87
00:04:39,334 --> 00:04:42,049
そこで FloatTensorまで
equalsを変換します

88
00:04:42,050 --> 00:04:45,199
これで精度は確認できます

89
00:04:45,199 --> 00:04:47,180
このバッチは15.6%です

90
00:04:47,180 --> 00:04:49,009
予測はおおまかに
このようになります

91
00:04:49,009 --> 00:04:51,589
ネットワークはまだ
トレーニングされていません

92
00:04:51,589 --> 00:04:56,060
ランダムな推測を行っています

93
00:04:56,060 --> 00:05:01,910
特定の画像は 約10枚のうち１つ
であると確認できる程度の精度です

94
00:05:01,910 --> 00:05:05,105
クラスの１つの不均一な
推測にすぎないからです

95
00:05:05,105 --> 00:05:07,970
ここではこの検証ループを
実際に実装してみます

96
00:05:07,970 --> 00:05:12,260
データをテストセットからネットワークに

97
00:05:12,259 --> 00:05:15,024
渡して損失と精度を計算します

98
00:05:15,024 --> 00:05:18,859
気をつけないといけない点があります
前にも指摘したかと思います

99
00:05:18,860 --> 00:05:20,435
検証パスでは
トレーニングを何も行いません

100
00:05:20,435 --> 00:05:24,694
勾配は必要ありません

101
00:05:24,694 --> 00:05:26,569
勾配をオフにするとコードを
少し加速できます

102
00:05:26,569 --> 00:05:30,214
このコンテキストを利用します

103
00:05:30,214 --> 00:05:34,435
torch.no_gradでは検証パスを
ここに入力できます

104
00:05:34,435 --> 00:05:39,214
テストローダーの画像とラベル
そして検証パスをここにです

105
00:05:39,214 --> 00:05:43,459
分類子を基本的に構築していて
これらすべてを設置しています

106
00:05:43,459 --> 00:05:45,589
ここにトレーニングパスがあります
検証パスを実装するのはあなた次第です

107
00:05:45,589 --> 00:05:47,069
そして精度を出力します

108
00:05:47,069 --> 00:05:49,680
うまくいきますように

109
00:05:49,680 --> 00:05:51,600
つまずいたり サポートが必要になったら

