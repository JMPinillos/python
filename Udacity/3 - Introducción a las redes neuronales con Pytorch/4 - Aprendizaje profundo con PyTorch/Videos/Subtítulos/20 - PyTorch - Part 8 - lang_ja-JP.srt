1
00:00:00,000 --> 00:00:01,485
こんにちは

2
00:00:01,485 --> 00:00:06,060
ここでは 事前に学習された
ネットワークを使って

3
00:00:06,059 --> 00:00:11,079
猫と犬の画像を分類するという
難しい問題を解決します

4
00:00:11,080 --> 00:00:14,730
このネットワークは 1,000種類のカテゴリで
100万枚以上のラベル付き画像を

5
00:00:14,730 --> 00:00:19,605
集めた大規模なデータセット
ImageNetで事前学習済みです

6
00:00:19,605 --> 00:00:27,105
これらは torchvisionとモジュールの
torchvision.modelsから入手できます

7
00:00:27,105 --> 00:00:32,560
このように ６種類の異なる
アーキテクチャを使用でき

8
00:00:32,560 --> 00:00:36,790
各モデルのパフォーマンスの
内訳は次のとおりです

9
00:00:36,789 --> 00:00:40,644
AlexNetはトップのエラーと
５つのエラーを表示します

10
00:00:40,645 --> 00:00:42,520
ご覧のように

11
00:00:42,520 --> 00:00:45,820
これらのネットワークや

12
00:00:45,820 --> 00:00:48,335
19 11 34などの数字は

13
00:00:48,335 --> 00:00:51,429
通常 このモデルの
レイヤー数を示しています

14
00:00:51,429 --> 00:00:52,600
数字が大きくなれば

15
00:00:52,600 --> 00:00:54,085
モデルも大きくなります

16
00:00:54,085 --> 00:00:56,634
モデルが大きければ

17
00:00:56,634 --> 00:00:58,734
精度も高くなり

18
00:00:58,734 --> 00:01:00,005
エラーが減少します

19
00:01:00,005 --> 00:01:01,664
同時に

20
00:01:01,664 --> 00:01:03,255
モデルが大きくなると

21
00:01:03,255 --> 00:01:08,310
予測や訓練に時間がかかる
ようになります

22
00:01:08,310 --> 00:01:09,945
これらを使うと

23
00:01:09,944 --> 00:01:14,879
精度とスピードのトレードオフを
考える必要があります

24
00:01:14,879 --> 00:01:20,015
これらのネットワークはすべて
畳み込み層というアーキテクチャを使います

25
00:01:20,015 --> 00:01:24,269
画像のパターンや規則性を
利用したものです

26
00:01:24,269 --> 00:01:27,104
詳細は割愛しますが 興味があるなら

27
00:01:27,105 --> 00:01:28,760
ビデオを視聴しましょう

28
00:01:28,760 --> 00:01:33,359
つまりこれらの深層学習ネットワークは
非常に深いものなのです

29
00:01:33,359 --> 00:01:37,489
数百もの異なる層を持ち

30
00:01:37,489 --> 00:01:40,659
膨大なImageNetデータセットで
訓練されています

31
00:01:40,659 --> 00:01:43,369
訓練されていない画像に対しても

32
00:01:43,370 --> 00:01:46,715
将来検出できるようになるのは
素晴らしいですね

33
00:01:46,715 --> 00:01:49,445
事前に学習したネットワークを

34
00:01:49,444 --> 00:01:52,524
初めての対象に使用することを
転移学習と呼びます

35
00:01:52,525 --> 00:01:54,620
ImageNetデータセットから
学習したことが

36
00:01:54,620 --> 00:01:58,730
データセットに引き継がれるのです

37
00:01:58,730 --> 00:02:01,549
ここでは 転移学習を使って

38
00:02:01,549 --> 00:02:04,774
猫と犬の写真を分類する
独自のネットワークを学習します

39
00:02:04,775 --> 00:02:09,375
ほとんど手をかけなくても
優れたパフォーマンスが得られます

40
00:02:09,375 --> 00:02:13,145
このモデルは
torchvision.modelsから

41
00:02:13,145 --> 00:02:17,170
ダウンロードできるので
これをインポートに含めます

42
00:02:17,169 --> 00:02:22,459
事前学習されたモデルのほとんどは
224×224枚の画像の入力が必要です

43
00:02:22,460 --> 00:02:24,500
これらのモデルをImageNetで

44
00:02:24,500 --> 00:02:26,719
トレーニングした時の正規化と
一致させる必要があります

45
00:02:26,719 --> 00:02:29,109
モデルを訓練する際は

46
00:02:29,110 --> 00:02:32,370
各色チャンネルと
画像を別々に正規化します

47
00:02:32,370 --> 00:02:36,500
こに平均値 ここに標準偏差が
表示されます

48
00:02:36,500 --> 00:02:38,629
トレーニングデータと
テストデータの

49
00:02:38,629 --> 00:02:42,115
変換の定義は皆さんに
お任せしますが

50
00:02:42,115 --> 00:02:44,745
これで新しい定義ができます

51
00:02:44,745 --> 00:02:48,560
実際に これらのモデルを
ロードする方法を見ましょう

52
00:02:48,560 --> 00:02:52,879
ここでは Densenet-121モデルを
使用します

53
00:02:52,879 --> 00:02:56,085
ImageNetデータセットは
非常に高い精度を示し

54
00:02:56,085 --> 00:03:03,375
121という数字は121のレイヤーを
意味します

55
00:03:03,375 --> 00:03:06,064
これをコードに読み込むには

56
00:03:06,064 --> 00:03:14,280
models.densenet121というモデルを指定し

57
00:03:14,280 --> 00:03:17,360
pretrained=trueとします

58
00:03:17,360 --> 00:03:19,534
これは 事前訓練されたネットワークと

59
00:03:19,533 --> 00:03:21,594
重み そしてパラメータ自体を
ダウンロードして

60
00:03:21,594 --> 00:03:27,335
モデルにロードするものです

61
00:03:27,335 --> 00:03:31,515
ここでモデルのアーキテクチャを
見てみましょう

62
00:03:31,514 --> 00:03:36,500
これが DenseNetアーキテクチャの
詳細です

63
00:03:36,500 --> 00:03:39,409
ここには特徴があり
さらに多くの層があります

64
00:03:39,409 --> 00:03:44,025
これは畳み込み層のようなもので

65
00:03:44,025 --> 00:03:46,500
ここでは割愛しますが
理解しなくても使用できます

66
00:03:46,500 --> 00:03:48,314
ここでは
主に２つの部分に注目します

67
00:03:48,314 --> 00:03:50,370
まず 特徴量ですが

68
00:03:50,370 --> 00:03:53,025
一番下までスクロールすると

69
00:03:53,025 --> 00:03:56,010
分類子のパートがあります

70
00:03:56,009 --> 00:03:59,399
ここに分類子があります

71
00:03:59,400 --> 00:04:01,004
これは線型結合層として
定義されており

72
00:04:01,004 --> 00:04:05,324
完全に密な層で

73
00:04:05,324 --> 00:04:09,329
1,024個の入力特徴と
1,000個の出力特徴があります

74
00:04:09,330 --> 00:04:12,420
ImageNetデータセットには
1,000種類のクラスがあります

75
00:04:12,419 --> 00:04:15,629
つまり このネットワークの
出力数は

76
00:04:15,629 --> 00:04:19,540
それぞれのクラスに対して
1,000になります

77
00:04:19,540 --> 00:04:22,060
重要なのは すべてがImageNetで
訓練されているということです

78
00:04:22,060 --> 00:04:26,740
この特徴は他のデータセットでも
使えますが

79
00:04:26,740 --> 00:04:29,829
分類子自体はImageNet用に
訓練されています

80
00:04:29,829 --> 00:04:32,199
つまり 分類子を再訓練する
必要があります

81
00:04:32,199 --> 00:04:33,670
特徴のパートは
静的にしておきたいので

82
00:04:33,670 --> 00:04:36,225
更新はしませんが

83
00:04:36,225 --> 00:04:41,035
分類子のみ更新する必要があります

84
00:04:41,035 --> 00:04:47,675
最初にすべきことは特徴のパラメータを
固定することです

85
00:04:47,675 --> 00:04:54,000
そのためには モデルの
パラメータを見てみます

86
00:04:54,000 --> 00:04:59,964
例えば requires_grad=false
とします

87
00:04:59,964 --> 00:05:03,250
こうすると テンソルをモデルで
実行する際

88
00:05:03,250 --> 00:05:05,860
勾配を計算しなくて済むように
なります

89
00:05:05,860 --> 00:05:08,230
すべての演算を追跡するわけでは
ありません

90
00:05:08,230 --> 00:05:12,415
これで特徴のパラメータが

91
00:05:12,415 --> 00:05:15,835
更新されなくなり
特徴の演算を

92
00:05:15,834 --> 00:05:19,689
追跡する必要がないため

93
00:05:19,689 --> 00:05:23,394
トレーニングのスピードアップ
にもつながります

94
00:05:23,394 --> 00:05:26,410
次に 分類子を独自のものに
置き換える必要があります

95
00:05:26,410 --> 00:05:30,525
ここで 新しいものをいくつか
用意していますが

96
00:05:30,524 --> 00:05:32,334
PyTorchのシーケンシャル
モジュールを使用します

97
00:05:32,334 --> 00:05:34,899
基本的には 実行したい

98
00:05:34,899 --> 00:05:39,608
さまざまな演算のリストを
与えるだけで

99
00:05:39,608 --> 00:05:45,375
自動的に連続して
テンソルが渡されます

100
00:05:45,375 --> 00:05:47,115
順序付きdictを渡し
各層に名前を付けることができます

101
00:05:47,115 --> 00:05:49,704
仕組みをお見せしましょう

102
00:05:49,704 --> 00:05:51,534
完全結合層が必要なので

103
00:05:51,535 --> 00:05:54,939
FC1と名前を付けます

104
00:05:54,939 --> 00:05:59,425
これは1,024の
入力から成る

105
00:05:59,425 --> 00:06:04,900
完全結合層で
隠れ層は500とします

106
00:06:04,899 --> 00:06:06,699
これをReLuの活性化関数に渡し

107
00:06:06,699 --> 00:06:10,404
次に完全結合層を経て

108
00:06:10,404 --> 00:06:13,089
これが出力層になります

109
00:06:13,089 --> 00:06:14,379
500から２にします

110
00:06:14,379 --> 00:06:15,935
犬と猫に分類するので

111
00:06:15,935 --> 00:06:20,740
２種類の出力が必要です

112
00:06:20,740 --> 00:06:24,009
最後に 出力は以前と同じ
LogSoftmaxになります

113
00:06:24,009 --> 00:06:26,139
これが 分類子の定義方法です

114
00:06:26,139 --> 00:06:30,500
これで 完全結合層から

115
00:06:30,500 --> 00:06:37,189
構築された分類子を

116
00:06:37,189 --> 00:06:40,475
model.classifierに
適用することができます

117
00:06:40,475 --> 00:06:45,935
訓練を受けていない
新しい分類子をモデルに適用します

118
00:06:45,935 --> 00:06:48,769
このモデルにも
特徴パートがあります

119
00:06:48,769 --> 00:06:52,914
特徴のパートは固定されます

120
00:06:52,915 --> 00:06:56,030
この重みを更新するのではなく
新しい分類子を訓練する必要があります

121
00:06:56,029 --> 00:06:59,929
今使っているネットワークを
訓練したい場合は

122
00:06:59,930 --> 00:07:02,949
このDensenet-121は深く
121の層があります

123
00:07:02,949 --> 00:07:04,694
これを CPUで学習させると

124
00:07:04,694 --> 00:07:07,514
相当な時間がかかります

125
00:07:07,514 --> 00:07:12,599
ここでは GPUを使います

126
00:07:12,600 --> 00:07:15,150
GPUは線型代数の計算を並列で
実行するために作られており

127
00:07:15,149 --> 00:07:18,104
ニューラルネットワークも
基本的には

128
00:07:18,105 --> 00:07:20,310
線型代数の演算を集めた
ものです

129
00:07:20,310 --> 00:07:25,170
これをGPUで実行すると

130
00:07:25,170 --> 00:07:29,310
並列で実行されるため
速度が約100倍になります

131
00:07:29,310 --> 00:07:31,875
PyTorchでは GPUを使うのは
非常に簡単です

132
00:07:31,875 --> 00:07:35,470
例えば モデルのテンソルに

133
00:07:35,470 --> 00:07:39,220
すべてのパラメータがあり

134
00:07:39,220 --> 00:07:44,035
コンピュータのメモリに格納
されているとしたら

135
00:07:44,035 --> 00:07:48,790
model.cudaを使ってGPUに
移動させることができます

136
00:07:48,790 --> 00:07:53,905
つまり モデルのパラメータを
GPUに移し

137
00:07:53,904 --> 00:07:59,244
すべての計算と処理を
GPU上で行うということです

138
00:07:59,245 --> 00:08:01,869
​同様に 画像などのテンソルの場合は
画像を選択し

139
00:08:01,869 --> 00:08:04,720
モデル内で画像を実行するなら

140
00:08:04,720 --> 00:08:07,690
モデル内に配置するテンソル
またはモデルがGPU上にあるなら

141
00:08:07,689 --> 00:08:09,370
GPU上に配置するテンソルを
確認する必要があります

142
00:08:09,370 --> 00:08:13,209
これを一致させる必要があります

143
00:08:13,209 --> 00:08:15,699
そのため テンソルを
コンピュータからGPUに移動させるには

144
00:08:15,699 --> 00:08:17,834
ここでもimages.cudaを使います

145
00:08:17,834 --> 00:08:19,859
これでテンソル

146
00:08:19,860 --> 00:08:24,610
つまり画像をGPUに移します

147
00:08:24,610 --> 00:08:29,035
モデルやテンソルをGPUから

148
00:08:29,035 --> 00:08:35,279
ローカルのメモリやCPUに
戻したい場合は

149
00:08:35,279 --> 00:08:39,514
model.cpuやimages.cpuを使い

150
00:08:39,514 --> 00:08:43,804
テンソルをGPUから

151
00:08:43,804 --> 00:08:47,419
ローカルのコンピュータに戻し
CPUで実行させることができます

152
00:08:47,419 --> 00:08:53,860
今度は その仕組みと
GPUを使うことで得られる

153
00:08:53,860 --> 00:08:58,850
驚異的な高速化の
デモ実演をお見せします

154
00:08:58,850 --> 00:09:01,370
ここで cuda [false, true] と
指定します

155
00:09:01,370 --> 00:09:04,190
この方法では
基本的にループを回して

156
00:09:04,190 --> 00:09:06,085
GPUを使用しない場合と
GPUを使用する場合の

157
00:09:06,085 --> 00:09:09,045
両方を試すことができます

158
00:09:09,044 --> 00:09:13,594
通常のように自然な

159
00:09:13,595 --> 00:09:19,129
log_lossになる基準を定義し
最適化を定義しましょう

160
00:09:19,129 --> 00:09:23,284
再度 分類子のパラメータのみを
更新することに注意してください

161
00:09:23,284 --> 00:09:27,799
model.classifier.parametersを
指定します

162
00:09:27,799 --> 00:09:32,344
これで 分類子の前提条件は
更新されますが

163
00:09:32,345 --> 00:09:34,759
モデルの特徴検出部分の
パラメータは固定されます

164
00:09:34,759 --> 00:09:39,004
通常は 例えばcudaであれば

165
00:09:39,004 --> 00:09:42,394
モデルをGPUに移動させます

166
00:09:42,394 --> 00:09:46,985
それ以外では CPUに任せます

167
00:09:46,985 --> 00:09:51,110
そして 少しトレーニングループを
書いてみます

168
00:09:51,110 --> 00:09:55,350
入力とラベルを取得し

169
00:09:55,350 --> 00:09:58,139
通常のように変数に変更します

170
00:09:58,139 --> 00:09:59,865
また cudaが有効であれば

171
00:09:59,865 --> 00:10:02,705
つまり GPUがあれば

172
00:10:02,705 --> 00:10:06,585
入力とラベルを設定し

173
00:10:06,585 --> 00:10:11,514
これらをGPUに移動させます

174
00:10:11,514 --> 00:10:15,174
現在はGPUを使用し
この事前学習済みの

175
00:10:15,174 --> 00:10:19,254
ネットワークも使用していますが
これまで構築してきた

176
00:10:19,254 --> 00:10:24,580
フィードフォワードネットワークと
全く同じ方法で学習ループを行います

177
00:10:24,580 --> 00:10:28,315
まず 時間を計るために
開始時間を設定し

178
00:10:28,315 --> 00:10:33,170
通常通りに
トレーニングパスを行います

179
00:10:33,169 --> 00:10:35,189
モデルにフォワードパスを
するだけで 損失を計算し

180
00:10:35,190 --> 00:10:38,760
バックワードパスが
実行できます

181
00:10:38,759 --> 00:10:42,610
最後に 最適化で重みを
更新します

182
00:10:42,610 --> 00:10:47,950
最初の３回の繰り返しの後に

183
00:10:47,950 --> 00:10:53,815
このトレーニングループを
中断します

184
00:10:53,815 --> 00:10:56,440
GPUを使う場合と使わない場合の
差を測定したいと思います

185
00:10:56,440 --> 00:10:59,200
​トレーニングループを最初に
通過するバッチは

186
00:10:59,200 --> 00:11:03,070
他のバッチよりも時間がかかる
傾向があるので

187
00:11:03,070 --> 00:11:08,260
最初の３つか４つを平均して

188
00:11:09,649 --> 00:11:14,439
１つのバッチの処理にかかる
時間を把握します

189
00:11:14,440 --> 00:11:17,635
これがトレーニングの所要時間に
なります

190
00:11:17,634 --> 00:11:23,710
GPUを使用しない場合
各バッチが

191
00:11:23,710 --> 00:11:26,410
このトレーニングステップを
通過するのに5.5秒かかります

192
00:11:26,409 --> 00:11:29,469
一方 GPUの場合は

193
00:11:29,470 --> 00:11:33,095
0.012秒で完了するので

194
00:11:33,095 --> 00:11:37,810
100倍以上も速くなるのです

195
00:11:37,809 --> 00:11:43,134
ここでは手動でcudaを
設定していますが

196
00:11:43,134 --> 00:11:45,924
GPUが利用可能かどうかを
チェックすることもできます

197
00:11:45,924 --> 00:11:49,949
torch.cudaが利用できる場合は
条件に応じて

198
00:11:49,950 --> 00:11:51,845
trueまたはfalseが返されます

199
00:11:51,845 --> 00:11:55,375
ここからは

200
00:11:55,375 --> 00:11:58,779
皆さんでモデルを完成させてください

201
00:11:58,779 --> 00:12:02,799
すでにロードされている
DenseNetモデルを継続するか

202
00:12:02,799 --> 00:12:04,689
ResNetを試してみるのも
よいでしょう

203
00:12:04,690 --> 00:12:06,025
私はVGGNetも好きです

204
00:12:06,024 --> 00:12:07,799
かなり使えると思いますが

