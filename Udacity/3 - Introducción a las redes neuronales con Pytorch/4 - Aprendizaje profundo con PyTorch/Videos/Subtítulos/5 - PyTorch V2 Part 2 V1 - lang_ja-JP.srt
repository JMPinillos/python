1
00:00:00,000 --> 00:00:02,205
こんにちは

2
00:00:02,205 --> 00:00:05,099
早速始めましょう

3
00:00:05,099 --> 00:00:11,279
このノートと動画では

4
00:00:11,279 --> 00:00:14,820
ニューラルネットワークとPyTorchの
更に強力な構築方法について説明します

5
00:00:14,820 --> 00:00:18,464
最後のノートでは テンソルと
行列の乗算を使用した

6
00:00:18,464 --> 00:00:21,509
出力の計算方法を確認しました

7
00:00:21,510 --> 00:00:26,160
しかし PyTorchには
この優れたモジュールnnがあり

8
00:00:26,160 --> 00:00:31,050
これに含まれるたくさんの
クラス メソッドや関数によって

9
00:00:31,050 --> 00:00:32,579
大規模なニューラルネットワークを
効率良く構築することができます

10
00:00:32,579 --> 00:00:35,144
機能する仕組みを示すために
MNISTと呼ばれる データセットを使用します

11
00:00:35,145 --> 00:00:39,920
MNISTは グレースケールの
手書き数字の集まりです

12
00:00:39,920 --> 00:00:41,270
つまり０ １ ２ ３

13
00:00:41,270 --> 00:00:43,350
４…と続いて９まであります

14
00:00:43,350 --> 00:00:47,570
これらの各画像は 28x28ピクセルで

15
00:00:47,570 --> 00:00:51,969
目的は これらの画像にある数字を
特定することです

16
00:00:51,969 --> 00:00:55,699
データセットは これらの画像の
１つ１つで構成されるもので

17
00:00:55,700 --> 00:00:59,620
画像にある数字が そのラベルになっています

18
00:00:59,619 --> 00:01:01,379
つまり１のラベルは１

19
00:01:01,380 --> 00:01:03,120
２のラベルは２…となります

20
00:01:03,119 --> 00:01:05,435
ネットワークに画像と 正しいラベルを表示して

21
00:01:05,435 --> 00:01:09,290
数字と画像が何であるかを
判断する方法を学習させます

22
00:01:09,290 --> 00:01:15,680
データセットは Torchvisionの
パッケージから入手できます

23
00:01:15,680 --> 00:01:19,010
つまり これはPyTorchに寄り添った
パッケージだということです

24
00:01:19,010 --> 00:01:23,575
これには データセットや

25
00:01:23,575 --> 00:01:26,420
コンピュータビジョンの問題用のモデルなど
たくさんの便利なアイテムが含まれています

26
00:01:26,420 --> 00:01:29,989
このセルを実行して MNISTデータセットを
ダウンロードして 実行することができます

27
00:01:29,989 --> 00:01:35,299
これによって trainloaderと呼ばれる
オブジェクトが返されます

28
00:01:35,299 --> 00:01:38,929
trainloaderがあると iterのイテレータに変換でき

29
00:01:38,930 --> 00:01:43,625
これによって うまく処理ができるようになります

30
00:01:43,625 --> 00:01:45,650
実際には 単純にこのループを
forループで使用して

31
00:01:45,650 --> 00:01:48,260
この for image, label in trainloaderの

32
00:01:48,260 --> 00:01:51,890
ジェネレータから 画像とラベルを取得することができます

33
00:01:51,890 --> 00:01:55,668
注意すべきことは
trainloaderを作成したとき

34
00:01:55,668 --> 00:01:57,634
batch_sizeを 64に設定した点です

35
00:01:57,635 --> 00:02:00,500
これは 画像とラベルのセットを
データローダから取得するたびに

36
00:02:00,500 --> 00:02:03,170
64の画像を得る ということを意味しています

37
00:02:03,170 --> 00:02:07,579
これらの画像の形とサイズに注目すると

38
00:02:07,579 --> 00:02:12,204
（64, 1, 28, 28）だと分かります

39
00:02:12,205 --> 00:02:16,520
64の画像 １つのカラーチャネル
つまりグレースケールで

40
00:02:16,520 --> 00:02:20,620
そして28×28ピクセルが これらの画像の形です　

41
00:02:20,620 --> 00:02:25,325
ここに表示されています

42
00:02:25,324 --> 00:02:31,089
ラベルが64ということは 各画像の
ラベルを備えた

43
00:02:31,090 --> 00:02:37,085
64エレメントのベクトルです

44
00:02:37,085 --> 00:02:39,980
画像の１例を示します　これは４ですね

45
00:02:39,979 --> 00:02:42,979
ここですることは

46
00:02:42,979 --> 00:02:44,824
前に見たメソッドを使用して 多層の
ニューラルネットワークの構築です

47
00:02:44,824 --> 00:02:48,214
どういうことかと言うと ウェイトの行列と
バイアスのベクトルを初期化した後

48
00:02:48,215 --> 00:02:52,849
これらを使用して その多層ネットワークの
出力を計算します

49
00:02:52,849 --> 00:02:59,574
具体的には このネットワークを
784の入力ユニットと 256の隠れユニット

50
00:02:59,574 --> 00:03:05,310
10の出力ユニットを 有するものにします

51
00:03:05,310 --> 00:03:08,280
10の出力ユニットは

52
00:03:08,280 --> 00:03:09,719
各クラスに対応します

53
00:03:09,719 --> 00:03:12,064
784の入力ユニットは

54
00:03:12,064 --> 00:03:14,319
この種のネットワークが

55
00:03:14,319 --> 00:03:17,739
完全結合または 密につながった
ネットワークと呼ばれる理由になっています

56
00:03:17,740 --> 00:03:21,825
私たちは 入力を１つのベクトルとして
考えようとしています

57
00:03:21,824 --> 00:03:25,944
実際には画像は 28×28ですが

58
00:03:25,944 --> 00:03:29,919
ネットワークにベクトルを入れ込むために

59
00:03:29,919 --> 00:03:34,299
この28×28の画像を ベクトルに
変換するのです

60
00:03:34,300 --> 00:03:39,100
よって 28×28で784となります

61
00:03:39,099 --> 00:03:41,935
実際にこの28×28の画像を
ベクトルに平坦化すると

62
00:03:41,935 --> 00:03:46,295
その長さは 784エレメントになります

63
00:03:46,294 --> 00:03:50,609
ここで バッチのそれぞれ

64
00:03:50,610 --> 00:03:53,570
つまり ここでは（64, 1, 28, 28）の形状を

65
00:03:53,569 --> 00:03:56,539
別のテンソルである（64, 784）の形状に
変換する必要があります

66
00:03:56,539 --> 00:04:03,090
これが ネットワークへの入力である
テンソルとなります

67
00:04:03,090 --> 00:04:07,009
では やってみてください

68
00:04:07,009 --> 00:04:09,155
繰り返しますが 784の入力ユニットの

69
00:04:09,155 --> 00:04:12,379
256の隠れユニットと 10の出力ユニットの

70
00:04:12,379 --> 00:04:17,180
ネットワークを構築して 独自のランダムな
初期ウェイトとバイアス行列を生成することになります

71
00:04:17,180 --> 00:04:23,269
それでは！

