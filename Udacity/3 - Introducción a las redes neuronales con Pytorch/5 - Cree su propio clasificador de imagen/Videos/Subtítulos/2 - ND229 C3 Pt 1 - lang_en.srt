1
00:00:00,000 --> 00:00:04,110
In this project, you'll have the opportunity to demonstrate the skills you've

2
00:00:04,110 --> 00:00:08,925
developed in this course by building an object detection system using PyTorch.

3
00:00:08,925 --> 00:00:10,260
To do this project,

4
00:00:10,260 --> 00:00:13,890
you'll need to pull together the new deep learning skills you've just learned,

5
00:00:13,890 --> 00:00:16,260
such as data augmentation and building

6
00:00:16,260 --> 00:00:19,630
neural networks in order to solve a real-world problem.

7
00:00:19,630 --> 00:00:21,135
Here's the scenario.

8
00:00:21,135 --> 00:00:26,490
Imagine you're a machine-learning engineer working for a self-driving car startup.

9
00:00:26,490 --> 00:00:28,350
Your management team is looking for

10
00:00:28,350 --> 00:00:33,420
an object detection algorithm for stationary objects that may be on the side of the road.

11
00:00:33,420 --> 00:00:37,875
They're considering purchasing a computer vision algorithm from Detectocorp,

12
00:00:37,875 --> 00:00:43,945
which boasts a 70 percent accuracy rate on a benchmark dataset called CIFAR-10.

13
00:00:43,945 --> 00:00:47,900
They've asked you to take some time to determine whether or not they should buy

14
00:00:47,900 --> 00:00:51,825
the software or develop something in the house.

15
00:00:51,825 --> 00:00:55,070
Your job is to run your own in-house model on

16
00:00:55,070 --> 00:00:57,620
the same CIFAR-10 dataset used by

17
00:00:57,620 --> 00:01:02,230
Detectocorp to see how the accuracy compares with theirs.

18
00:01:02,230 --> 00:01:07,834
CIFAR-10 is a classic dataset used to benchmark results in computer vision research,

19
00:01:07,834 --> 00:01:13,490
it's a subset of the 80 million tiny images dataset and it was released by

20
00:01:13,490 --> 00:01:20,240
researchers at the Canadian Institute For Advanced Research or CIFAR in 2009.

21
00:01:20,240 --> 00:01:28,835
The 10 comes from the 10 classes that the images are divided into: birds, cars, cats,

22
00:01:28,835 --> 00:01:34,415
dear, dogs, frogs, horses,

23
00:01:34,415 --> 00:01:38,520
airplanes, ships, and trucks.

24
00:01:38,520 --> 00:01:42,500
Each image has an associated label so that you can compare

25
00:01:42,500 --> 00:01:47,630
the accuracy of your image classifier with the known identity of each image.

26
00:01:47,630 --> 00:01:53,600
There are 6,000 images in each of the 10 classes across the training and test sets.

27
00:01:53,600 --> 00:01:57,155
The dataset is built into many popular libraries,

28
00:01:57,155 --> 00:01:59,890
including the one we'll use, torchvision.

29
00:01:59,890 --> 00:02:01,970
As you can see from the images,

30
00:02:01,970 --> 00:02:04,290
the resolution is quite low;

31
00:02:04,290 --> 00:02:08,705
they're tiny images, only 32 pixels by 32 pixels.

32
00:02:08,705 --> 00:02:10,145
As I just mentioned,

33
00:02:10,145 --> 00:02:13,190
one of the keys to CIFAR-10 is it uses

34
00:02:13,190 --> 00:02:16,670
a benchmark for comparing computer vision algorithms.

35
00:02:16,670 --> 00:02:21,050
In this sense, it is similar to other classic datasets you may have heard of,

36
00:02:21,050 --> 00:02:23,665
such as MNIST or ImageNet.

37
00:02:23,665 --> 00:02:25,545
Over the past years,

38
00:02:25,545 --> 00:02:30,230
CIFAR-10 along with these other classic datasets like MNIST and ImageNet,

39
00:02:30,230 --> 00:02:34,685
have been widely used to test and improve scores of different models.

40
00:02:34,685 --> 00:02:38,150
In this table, we can see the progressive improvement from

41
00:02:38,150 --> 00:02:42,000
the relatively modest Convolutional Deep Belief Networks in

42
00:02:42,000 --> 00:02:51,230
2010 with an accuracy of 78.9 percent to the massive network GPipe released in 2018,

43
00:02:51,230 --> 00:02:56,065
which achieved an impressive 99 percent classification accuracy.

44
00:02:56,065 --> 00:03:01,220
Of course, GPipe is one of the largest computer vision models ever trained,

45
00:03:01,220 --> 00:03:05,495
so we should expect a nearly 20 percent increase in accuracy.

46
00:03:05,495 --> 00:03:08,465
Don't worry if you can't beat these results,

47
00:03:08,465 --> 00:03:13,145
these are advanced models with carefully chosen and tuned hyper-parameters

48
00:03:13,145 --> 00:03:18,530
trained by scientists in some of the most well-funded research labs on Earth.

49
00:03:18,530 --> 00:03:21,530
Since there are 10 classes in the dataset,

50
00:03:21,530 --> 00:03:25,330
random guessing gives us about a 10 percent accuracy rate,

51
00:03:25,330 --> 00:03:31,875
so anything over 50 percent is good and anything over 70 percent is really great.

52
00:03:31,875 --> 00:03:35,910
Let's see where you can put your name on the board.

