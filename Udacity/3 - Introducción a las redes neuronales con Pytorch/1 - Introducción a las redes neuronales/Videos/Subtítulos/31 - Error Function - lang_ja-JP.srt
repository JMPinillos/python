1
00:00:00,000 --> 00:00:03,632
これまでのレッスンを
簡単にまとめておきましょう

2
00:00:03,632 --> 00:00:05,640
ここに２つのモデルがあります

3
00:00:05,639 --> 00:00:08,934
左は悪いモデル 右は良いモデルです

4
00:00:08,935 --> 00:00:13,440
それぞれについて
クロスエントロピーを計算します

5
00:00:13,439 --> 00:00:19,259
クロスエントロピーは色分けした点の
確率の負数の合計です

6
00:00:19,260 --> 00:00:22,170
そして クロスエントロピーが

7
00:00:22,170 --> 00:00:25,860
ずっと小さいことから
右側の方が良いと結論付けます

8
00:00:25,859 --> 00:00:29,269
実際に誤差関数の式を
計算してみましょう

9
00:00:29,269 --> 00:00:31,559
２つの場合に分けてみます

10
00:00:31,559 --> 00:00:34,269
最初の場合はy=１のときです

11
00:00:34,270 --> 00:00:36,130
よって青の点から始める場合です

12
00:00:36,130 --> 00:00:42,480
このモデルでは 点が青である確率が
予測値ŷとなります

13
00:00:42,479 --> 00:00:47,849
これらの２つの点の確率は
それぞれ0.6と0.2ということです

14
00:00:47,850 --> 00:00:50,910
青の領域にある点の方が

15
00:00:50,909 --> 00:00:55,000
赤の領域にある点よりも
青である確率がより高いことが分かります

16
00:00:55,000 --> 00:01:00,500
そして誤差は 単にこの確率の負の対数です

17
00:01:00,500 --> 00:01:04,010
正確にはŷの負の対数となります

18
00:01:04,010 --> 00:01:09,665
この図では 0.6の負の対数と
0.2の負の対数です

19
00:01:09,665 --> 00:01:13,745
y=０の場合 つまり点が赤である場合は

20
00:01:13,745 --> 00:01:17,585
点が赤である確率を 計算する必要があります

21
00:01:17,584 --> 00:01:22,339
点が赤である確率は１から
点が青である確率を引いたものです

22
00:01:22,340 --> 00:01:27,750
つまり 1-ŷとなります

23
00:01:27,750 --> 00:01:30,890
誤差は確率の負の対数ですから

24
00:01:30,890 --> 00:01:35,870
1-ŷの負の対数となります

25
00:01:35,870 --> 00:01:42,040
この場合では 0.1の負の対数と
0.7の負の対数となります

26
00:01:42,040 --> 00:01:46,605
よって 点が青である場合の誤差は
ŷの負の対数です

27
00:01:46,605 --> 00:01:50,635
点が赤の場合は 1-ŷの負の対数です

28
00:01:50,635 --> 00:01:53,625
これらの２つの式を１つにまとめます

29
00:01:53,625 --> 00:02:02,159
誤差＝-(1-y)(ln(1-ŷ)) - y ln(ŷ)
となります

30
00:02:02,159 --> 00:02:03,759
なぜこの式で計算が可能なのでしょう？

31
00:02:03,760 --> 00:02:05,730
それは 点が青であれば

32
00:02:05,730 --> 00:02:10,664
y=１となり つまり1-y=０ですから

33
00:02:10,664 --> 00:02:16,495
最初の項は０で ２つ目の項は
単純にŷの対数です

34
00:02:16,495 --> 00:02:20,219
同様に 点が赤ならy=０です

35
00:02:20,219 --> 00:02:27,680
よって式の２つ目の項は０で
１つ目の項は1-ŷの対数です

36
00:02:27,680 --> 00:02:31,145
ここで 誤差関数の式は点の誤差関数の

37
00:02:31,145 --> 00:02:35,510
総和であり 正確にはこのようになります

38
00:02:35,509 --> 00:02:38,564
これがここにある4.8と等しくなります

39
00:02:38,564 --> 00:02:41,469
慣例的には 総和ではなく

40
00:02:41,469 --> 00:02:45,330
平均値を考えますので このnで
全体を割ります

41
00:02:45,330 --> 00:02:49,050
この計算により4.8が1.2となります

42
00:02:49,050 --> 00:02:53,330
これ以降は この式を
誤差関数として使用します

43
00:02:53,330 --> 00:02:58,860
ここで ŷは線形関数Wx+bのシグモイドから
得たものですから

44
00:02:58,860 --> 00:03:01,890
誤差の式は モデルのウェイトである

45
00:03:01,889 --> 00:03:05,094
wとbで表すことができます

46
00:03:05,094 --> 00:03:08,219
そしてこのようにまとめることができます

47
00:03:08,219 --> 00:03:14,449
この場合 yᵢは点x(i)のラベルに過ぎません

48
00:03:14,449 --> 00:03:17,364
これで誤差関数が計算できましたが
目標はこれを最小化することです

49
00:03:17,365 --> 00:03:18,975
ではやってみましょう

50
00:03:18,974 --> 00:03:20,293
余談ですが

51
00:03:20,294 --> 00:03:23,210
ここで取り組んだのは二項分類問題です

52
00:03:23,210 --> 00:03:25,670
マルチクラスの分類問題の場合は

53
00:03:25,669 --> 00:03:28,490
誤差はマルチクラスの
エントロピーで得ることになります

54
00:03:28,491 --> 00:03:33,380
式はこのようになります

55
00:03:33,379 --> 00:03:39,139
各データの点について ラベルと

56
00:03:39,139 --> 00:03:41,539
予測の対数の積を求め
平均値を計算します

57
00:03:41,539 --> 00:03:45,000
繰り返しますが クラスが２つだけのときに

