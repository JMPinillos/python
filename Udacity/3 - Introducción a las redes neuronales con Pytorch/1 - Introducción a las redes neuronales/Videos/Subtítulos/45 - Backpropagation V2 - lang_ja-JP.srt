1
00:00:00,000 --> 00:00:04,309
ニューラルネットワークのトレーニングの準備が完了しました

2
00:00:04,309 --> 00:00:06,449
フィードフォワードについて 簡単に思い出してみましょう

3
00:00:06,450 --> 00:00:10,469
正のラベルのついた 点のパーセプトロンがあります

4
00:00:10,470 --> 00:00:15,050
式は w₁x₁+w₂x₂+b で

5
00:00:15,050 --> 00:00:19,804
w₁とw₂は重みで bはバイアスです

6
00:00:19,804 --> 00:00:21,009
パーセプトロンは 点をプロットして 青の確率を返します

7
00:00:21,010 --> 00:00:25,405
この場合 点は赤の領域にあるため小さいです

8
00:00:25,405 --> 00:00:29,345
実際は青なのに 赤であると予測するため

9
00:00:29,344 --> 00:00:32,070
これは不正なパーセプトロンだといえます

10
00:00:32,070 --> 00:00:36,164
勾配降下法アルゴリズムでの実行を
思い返してみましょう

11
00:00:36,164 --> 00:00:39,609
誤差逆伝播法です

12
00:00:39,609 --> 00:00:42,284
逆方向の処理です

13
00:00:42,284 --> 00:00:44,879
「モデルに何をさせたいですか？」に対して

14
00:00:44,880 --> 00:00:48,885
「分類が間違っているので この境界を近づけたい」と要求します

15
00:00:48,884 --> 00:00:50,829
重みを更新することで 線が近づいたのが確認できました

16
00:00:50,829 --> 00:00:55,204
つまり この場合

17
00:00:55,204 --> 00:00:59,894
重みw₁を低くし 重みw₂を高くするとします

18
00:00:59,895 --> 00:01:01,625
これはただの図で

19
00:01:01,625 --> 00:01:07,239
正確ではないときがあります

20
00:01:07,239 --> 00:01:08,694
ですから 新しい重みw₁'と w₂'で

21
00:01:08,694 --> 00:01:10,379
点に近くなるように 新しい線を定義します

22
00:01:10,379 --> 00:01:12,045
エラーレストという山を 下りているようなものです

23
00:01:12,045 --> 00:01:19,490
高さは 誤差関数E(W)となり

24
00:01:19,489 --> 00:01:22,170
誤差関数の勾配を計算します

25
00:01:22,170 --> 00:01:23,780
モデルに何を実行させたいかを聞くのと まったく同じです

26
00:01:23,780 --> 00:01:29,864
勾配の負の方向に下りるため

27
00:01:29,864 --> 00:01:32,679
エラーが減り 山を下りることになります

28
00:01:32,680 --> 00:01:35,857
これにより新しいエラーE(W')と

29
00:01:35,856 --> 00:01:40,340
エラーが小さくなった 新しいモデルW'が用意されます

30
00:01:40,340 --> 00:01:43,969
つまり 新しい線が点に近くなっていることを意味します

31
00:01:43,969 --> 00:01:45,304
エラーを最小限に抑えるため このプロセスを実行します

32
00:01:45,305 --> 00:01:49,932
これは パーセプトロンが１つの場合です

33
00:01:49,932 --> 00:01:53,480
多層パーセプトロンの場合は どうでしょうか？

34
00:01:53,480 --> 00:01:58,130
やはり山から下りることでエラーを
減らす同じプロセスを行います

35
00:01:58,129 --> 00:01:59,890
ただし 誤差関数が複雑なため

36
00:01:59,890 --> 00:02:02,760
エラーレスト山ではなく

37
00:02:02,760 --> 00:02:06,745
キリマンジェロ山ですが

38
00:02:06,745 --> 00:02:11,055
同様に 誤差関数と勾配を計算します

39
00:02:11,055 --> 00:02:12,775
勾配の負の方向に進み

40
00:02:12,775 --> 00:02:15,789
小さなエラーE(W')のある 新モデルW'を見つけます

41
00:02:15,788 --> 00:02:19,554
これにより より的確な予測を行えます

42
00:02:19,555 --> 00:02:25,290
エラーをなるべく減らすために このプロセスを続行します

43
00:02:25,289 --> 00:02:28,644
フィードフォワードが 多層パーセプトロンで
実行することを再度確認してみましょう

44
00:02:28,645 --> 00:02:32,719
点は 座標(x₁, x₂)で ラベルy＝1になります

45
00:02:32,719 --> 00:02:36,895
隠れ層に対応する線形モデルに プロットされます

46
00:02:36,895 --> 00:02:40,149
この層が結合されると

47
00:02:40,149 --> 00:02:45,990
出力層で生成される非線形モデルに 点がプロットされます

48
00:02:45,990 --> 00:02:50,570
点が青である確率は 最終モデルのこの場所により得られます

49
00:02:50,569 --> 00:02:54,019
これは トレーニングの重要な部分になりますので留意してください

50
00:02:54,020 --> 00:02:58,280
誤差逆伝播法というものです

51
00:02:58,280 --> 00:03:01,400
前やったように エラーをチェックします

52
00:03:01,400 --> 00:03:05,060
点は青なのに 赤であると予測するため 適切ではありません

53
00:03:05,060 --> 00:03:07,189
そこで 点に尋ねます

54
00:03:07,189 --> 00:03:11,094
より適切な分類を行うために このモデルに何をさせますか？

55
00:03:11,094 --> 00:03:13,849
点は 青の領域を近づけたいと答えます

56
00:03:13,849 --> 00:03:16,159
領域が近くなることに どんな意味があるのでしょうか？

57
00:03:16,159 --> 00:03:19,365
隠れ層の２つの線形モデルを見てみましょう

58
00:03:19,365 --> 00:03:21,320
これらの２つのモデルの どちらが良いでしょうか？

59
00:03:21,319 --> 00:03:26,579
上のモデルは 点を不適切に分類しているようです

60
00:03:26,580 --> 00:03:31,615
一方 下のモデルは 適切に分類しています

61
00:03:31,615 --> 00:03:35,195
下のモデルを留意し 上のモデルには注意を払わないようにしたいです

62
00:03:35,194 --> 00:03:39,049
上のモデルの重みを減らし

63
00:03:39,050 --> 00:03:42,735
下のモデルの重みを増やしたいです

64
00:03:42,735 --> 00:03:45,740
最終的なモデルは

65
00:03:45,740 --> 00:03:50,230
上のモデルよりも 下のモデルのように見えます

66
00:03:50,229 --> 00:03:55,454
もっといろんなことができます

67
00:03:55,455 --> 00:03:58,880
実際に線形モデルに移動して 点に尋ねます

68
00:03:58,879 --> 00:04:02,519
分類を適切にするために このモデルは何を実行できるのか？

69
00:04:02,520 --> 00:04:05,909
すると 点は上のモデルの分類は不適切なため

70
00:04:05,909 --> 00:04:10,034
この線を近づけたい

71
00:04:10,034 --> 00:04:12,014
２番目の分類は 適切であるため

72
00:04:12,014 --> 00:04:15,464
この線を遠くに移動したいと答えるでしょう

73
00:04:15,465 --> 00:04:20,250
モデルの変更には 実際に重みを更新します

74
00:04:20,250 --> 00:04:22,139
仮に２つを増やし ２つを減らすとします

75
00:04:22,139 --> 00:04:24,832
すべての重みを更新した後

76
00:04:24,833 --> 00:04:28,635
隠れ層の全モデルに対して より良い予測ができるようになり

77
00:04:28,634 --> 00:04:33,084
出力層のモデルでも より良い予測ができるようになります

78
00:04:33,084 --> 00:04:37,370
ここでは分かりやすくするために バイアスのユニットを説明していません

79
00:04:37,370 --> 00:04:41,670
実は 重みを更新するときには

80
00:04:41,670 --> 00:04:46,000
バイアスのユニットも更新することになります

81
00:04:46,000 --> 00:04:50,735
正確さを求める人も 心配しないでください

82
00:04:50,735 --> 00:04:53,569
これらの勾配についても すぐに詳細に計算を行います

83
00:04:53,569 --> 00:04:57,589

84
00:04:57,589 --> 00:05:02,125

85
00:05:02,125 --> 00:05:06,649

86
00:05:06,649 --> 00:05:08,659

87
00:05:08,660 --> 00:05:12,070

