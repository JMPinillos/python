1
00:00:00,000 --> 00:00:03,770
今の目標は「誤差関数の最小化」です
次のようにして行います

2
00:00:03,770 --> 00:00:05,415
ランダムな重み付けから始めます

3
00:00:05,415 --> 00:00:09,330
σ(Wx+b)という予測が得られます

4
00:00:09,330 --> 00:00:13,839
既に見たように この式から誤差関数も
得られます

5
00:00:13,839 --> 00:00:17,324
被加数も各点の誤差関数であることを
思い出してください

6
00:00:17,324 --> 00:00:20,339
各点が誤って分類されると大きな関数を

7
00:00:20,339 --> 00:00:24,009
正しく分類されると
小さな関数を得ることになります

8
00:00:24,010 --> 00:00:26,000
この関数を最小化するには

9
00:00:26,000 --> 00:00:27,679
勾配降下を使います

10
00:00:27,679 --> 00:00:31,114
エラーレスト山があって
これが私たちです

11
00:00:31,114 --> 00:00:33,439
誤差関数をどう小さくできるかを見るために

12
00:00:33,439 --> 00:00:36,439
軽く線を引いてみます

13
00:00:36,439 --> 00:00:40,979
誤差関数は標高で E(W, b) です

14
00:00:40,979 --> 00:00:43,699
W と b は 重みです

15
00:00:43,700 --> 00:00:46,520
ここで行うのは勾配降下を使うことで

16
00:00:46,520 --> 00:00:50,180
ずっと標高の低いところで山のふもとに
たどり着くためです

17
00:00:50,179 --> 00:00:56,000
より小さな誤差関数E(W', b')が得られます

18
00:00:56,000 --> 00:00:58,680
これで新たな重みW'とb'が付けられて

19
00:00:58,680 --> 00:01:03,334
より良い予測が得られます

20
00:01:03,335 --> 00:01:08,000
つまり σ(W'x+b') です

