1
00:00:00,000 --> 00:00:03,000
これでニューラルネットワークとは何かを
定義できたので

2
00:00:03,000 --> 00:00:04,810
訓練の方法を学んでいきましょう

3
00:00:04,810 --> 00:00:07,290
訓練の中身は データをうまく
モデル化するために

4
00:00:07,290 --> 00:00:10,495
どんなパラメータがエッジにあるべきか
ということです

5
00:00:10,495 --> 00:00:12,180
ニューラルネットワークを訓練する方法を
学ぶために

6
00:00:12,180 --> 00:00:16,800
入力から出力を得るためにどう処理されるか
注意深く見る必要があります

7
00:00:16,800 --> 00:00:19,820
では最も単純なニューラルネットワークで
ある パーセプトロンを見てみましょう

8
00:00:19,820 --> 00:00:23,400
パーセプトロンはフォーム x₁ と x₂ の
データポイントを受け取ります

9
00:00:23,400 --> 00:00:27,195
ラベルは y=1 です

10
00:00:27,195 --> 00:00:29,385
これは点は青色であることを意味します

11
00:00:29,385 --> 00:00:34,680
パーセプトロンは一次方程式で定義されます

12
00:00:34,680 --> 00:00:41,595
例えばw₁x₁ + w₂x₂ + bで

13
00:00:41,595 --> 00:00:43,555
w₁とw₂はエッジの重み
Ｂはノードのバイアスです

14
00:00:43,555 --> 00:00:46,200
w₁はw₂より大きいので

15
00:00:46,200 --> 00:00:49,820
ラベルw₂のエッジよりもラベルw₁のエッジを

16
00:00:49,820 --> 00:00:53,280
太く書いて示します

17
00:00:53,280 --> 00:00:57,240
ここでパーセプトロンが何をするかというと

18
00:00:57,240 --> 00:01:01,173
点(x₁, x₂) を描いて その点が青色の確率を
出力します

19
00:01:01,173 --> 00:01:03,795
点は赤い領域にあって 出力は小さな数です

20
00:01:03,795 --> 00:01:07,045
この点は青色ではあまりなさそうだからです

21
00:01:07,045 --> 00:01:11,070
このプロセスは順伝播型として
知られています

22
00:01:11,070 --> 00:01:12,570
これは悪いモデルだと分かります
点が青色だからです

23
00:01:12,570 --> 00:01:14,820
３つ目の座標である y が

24
00:01:14,820 --> 00:01:17,010
１の場合はそうなります

25
00:01:17,010 --> 00:01:18,570
さて より複雑なニューラルネットワークが
ある場合も

26
00:01:18,570 --> 00:01:22,050
プロセスは同じです

27
00:01:22,050 --> 00:01:26,280
ここで 大きな重みに対応する太いエッジと

28
00:01:26,280 --> 00:01:29,070
小さな重みに対応する細いエッジがあり

29
00:01:29,070 --> 00:01:35,025
ニューラルネットワークによって
点が上と下のグラフに描かれるとします

30
00:01:35,025 --> 00:01:38,580
上のモデルからの出力は小さな数でしょう

31
00:01:38,580 --> 00:01:43,140
点が赤の領域にあるということは青色である
確率が小さいことを意味しています

32
00:01:43,140 --> 00:01:44,895
２つ目のモデルからの大きな数は

33
00:01:44,895 --> 00:01:47,280
点が青の領域にあることから

34
00:01:47,280 --> 00:01:51,650
青色である確率が高いことを意味します

35
00:01:51,650 --> 00:01:53,180
さて この２つのモデルは組み合わせられて
非線型モデルになり

36
00:01:53,180 --> 00:01:57,485
出力レイヤーに点が描かれて

37
00:01:57,485 --> 00:02:00,620
この点が青色になる確率を示しています

38
00:02:00,620 --> 00:02:03,750
ご覧の通り これは悪いモデルです

39
00:02:03,750 --> 00:02:08,280
点は赤の領域に描かれていますが
青色だからです

40
00:02:08,280 --> 00:02:13,070
このプロセスも順伝播型と呼ばれます

41
00:02:13,070 --> 00:02:15,260
後でさらに詳しく見ていきます

42
00:02:15,260 --> 00:02:21,285
ここにニューラルネットワークと別の表記法
があり バイアスは外側にあります

43
00:02:21,285 --> 00:02:23,310
ここに 重みの行列があります

44
00:02:23,310 --> 00:02:26,175
行列Wの上付き文字は１つ目の層で

45
00:02:26,175 --> 00:02:30,110
エントリーは
重みW₁₁から W₃₂まであります

46
00:02:30,110 --> 00:02:31,520
バイアスは便宜上W₃₁およびW₃₂と
書かれていることに

47
00:02:31,520 --> 00:02:36,115
留意してください

48
00:02:36,115 --> 00:02:38,840
次の層にも行列があります

49
00:02:38,840 --> 00:02:43,700
Wの上付き文字は２で２つ目の層を
表します

50
00:02:43,700 --> 00:02:45,060
この層には重みが含まれ

51
00:02:45,060 --> 00:02:47,135
１つ目の層の
線型モデルの組み合わせから

52
00:02:47,135 --> 00:02:51,000
２つ目の層の非線型モデルを得る方法を
教えてくれます

53
00:02:51,000 --> 00:02:55,660
ここでちょっと数学です

54
00:02:55,660 --> 00:03:01,250
入力はx₁ x₂ １の形です

55
00:03:01,250 --> 00:03:04,130
１はバイアスユニットからのものです

56
00:03:04,130 --> 00:03:08,280
これに行列W₁を掛けて出力を得ます

57
00:03:08,280 --> 00:03:12,110
その際 出力を０～１の値にするために
シグモイド関数を使います

58
00:03:12,110 --> 00:03:16,290
ベクトル形式の出力値でバイアスユニットに
付いている１を得て

59
00:03:16,290 --> 00:03:21,155
２つ目のマトリックスを乗じます

60
00:03:21,155 --> 00:03:23,275
これが出力を返して
シグモイド関数へ投入され

61
00:03:23,275 --> 00:03:25,760
最終出力であるｙハットを得ます

62
00:03:25,760 --> 00:03:29,170
ｙハットはその点に青色のラベルが付く
という予測あるいは確率です

63
00:03:29,170 --> 00:03:32,825
これがニューラルネットワークが
行うことです

64
00:03:32,825 --> 00:03:37,310
入力ベクトルを使い

65
00:03:37,310 --> 00:03:42,995
線型モデルとシグモイド関数の
配列を使います

66
00:03:42,995 --> 00:03:48,025
これらのマップが結合されると
高度に非線型のマップになります

67
00:03:48,025 --> 00:03:51,105
そして最終的な式は単純になります

68
00:03:51,105 --> 00:03:53,380
ŷ = σ o W⁽²⁾ o σ o W⁽¹⁾(x) です

69
00:03:53,380 --> 00:03:55,560
ちなみに

70
00:03:55,560 --> 00:04:00,405
多層パーセプトロンやニューラル
ネットワークでも再度扱います

71
00:04:00,405 --> 00:04:05,360
予測であるｙハットを計算するには

72
00:04:05,360 --> 00:04:13,315
単位ベクトルｘから始めて

73
00:04:13,315 --> 00:04:16,430
２つ目の層の値を得るために

74
00:04:16,430 --> 00:04:20,000
１つ目の行列とシグモイド関数を
当てはめます

